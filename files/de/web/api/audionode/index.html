---
title: AudioNode
slug: Web/API/AudioNode
translation_of: Web/API/AudioNode
---
<p>{{ APIRef("Web Audio API") }}</p>

<p>Ein <strong><code>AudioNode</code></strong> ist eine generische Schnittstelle um ein Signalverarbeitungsmodul wie z.B. ein HTML {{HTMLElement("audio")}} or {{HTMLElement("video")}} Element, ein {{domxref("OscillatorNode")}}, die Audio Destination, ein zwischengeschaltenes audio-verarbeitendes Modul wie z.B. einen {{domxref("BiquadFilterNode")}} oder {{domxref("ConvolverNode")}}), oder Lautstärkeregler (like {{domxref("GainNode")}}).</p>

<p><img alt="AudioNodes participating in an AudioContext create a audio routing graph." src="https://mdn.mozillademos.org/files/9713/WebAudioBasics.png" style="display: block; height: 230px; margin: 0px auto; width: 677px;"></p>

<p>Ein <code>AudioNode</code> hat Ein- und Ausgänge, jeweils mit einer gegebenen Anzahl an Kanälen. Einen <code>AudioNode</code> ohne Eingänge und mit einem oder mehreren Ausgängen nennt man <em>source node </em>(dt.: Quellknoten). Die Art der Signalverarbeitung in einem Audio Node variiert mit dessen Funktion. Der folgende Ablauf liegt jedoch immer zugrunde:  das Signal am Eingang wird eingelesen,  das Signal wird zu einem neuen Signal verarbeitet und an den Ausgang geleitet. In einigen Fällen, wir das Signal unverarbeitet durchgeschleust, so z.B. beim {{domxref("AnalyserNode")}}, wo das Resultat der Signalverarbeitung separat zugänglich ist.</p>

<p>Mehrere Nodes können zu einem <em>Processing Graph </em>(dt.:Verarbeitungs-Netz) verbunden werden. Ein solcher Graph befindet sich immer in genau einem {{domxref("AudioContext")}}. Signal- verarbeitende Nodes erben die Eigenschaften und Methoden von <code>Audio Node</code>, implementieren aber auch eigene Funktionalität. Weitere Informationen geben die Seiten der speziellen <code>Audio Nodes</code>,  die sie auf der Homepage der <a href="/en-US/docs/Web/API/Web_Audio_API">Web Audio API</a> finden.</p>

<div class="note">
<p><span style="font-size: 14px; line-height: 21px;"><strong>Hinweis</strong></span>: Ein <code>AudioNode</code> kann das Ziel von Events sein, und implementiert daher die {{domxref("EventTarget")}} Schnittstelle.</p>
</div>

<h2 id="Properties" style="">Properties</h2>

<dl>
 <dt>{{domxref("AudioNode.context")}} {{readonlyInline}}</dt>
 <dd>Liefert den assoziierten {{domxref("AudioContext")}}, der den signalverarbeitenden Graphen (processing graph) enthält, in den der Node eingebunden ist.</dd>
</dl>

<dl>
 <dt>{{domxref("AudioNode.numberOfInputs")}} {{readonlyInline}}</dt>
 <dd>Liefert die Anzahl der Eingänge des Nodes. Source nodes (dt. Quellknoten) sind definiert als Nodes, deren <code>numberOfInputs</code> Eigenschaft einen Wert von <code>0 </code>aufweist.</dd>
</dl>

<dl>
 <dt>{{domxref("AudioNode.numberOfOutputs")}} {{readonlyInline}}</dt>
 <dd>Liefert die Anzahl der Ausgänge des Nodes. Destination nodes (dt.: Zielknoten) — wie {{ domxref("AudioDestinationNode") }} — haben einen Wert von  <code>0</code> für diese Eigenschaft.</dd>
</dl>

<dl>
 <dt>{{domxref("AudioNode.channelCount")}}</dt>
 <dd>Represents an integer used to determine how many channels are used when <a href="/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#Up-mixing_and_down-mixing">up-mixing and down-mixing</a> connections to any inputs to the node. Its usage and precise definition depend on the value of {{domxref("AudioNode.channelCountMode")}}.</dd>
</dl>

<dl>
 <dt>{{domxref("AudioNode.channelCountMode")}}</dt>
 <dd>Represents an enumerated value describing the way channels must be matched between the node's inputs and outputs.</dd>
 <dt>{{domxref("AudioNode.channelInterpretation")}}</dt>
 <dd>Represents an enumerated value describing the meaning of the channels. This interpretation will define how audio <a href="/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#Up-mixing_and_down-mixing">up-mixing and down-mixing</a> will happen.<br>
 The possible values are <code>"speakers"</code> or <code>"discrete"</code>.</dd>
</dl>

<h2 id="Methods">Methods</h2>

<p><em>Also implements methods from the interface </em>{{domxref("EventTarget")}}.</p>

<dl>
 <dt>{{domxref("AudioNode.connect(AudioNode)")}}</dt>
 <dd>Allows us to connect one output of this node to one input of another node.</dd>
 <dt>{{domxref("AudioNode.connect(AudioParam)")}}</dt>
 <dd>Allows us to connect one output of this node to one input of an audio parameter.</dd>
 <dt>{{domxref("AudioNode.disconnect()")}}</dt>
 <dd>Allows us to disconnect the current node from another one it is already connected to.</dd>
</dl>

<h2 id="Example">Example</h2>

<p>This simple snippet of code shows the creation of some audio nodes, and how the <code>AudioNode</code> properties and methods can be used. You can find examples of such usage on any of the examples linked to on the <a href="/en-US/docs/Web/API/Web_Audio_API">Web Audio API</a> landing page (for example <a href="https://github.com/mdn/violent-theremin">Violent Theremin</a>.)</p>

<pre class="brush: js;">var AudioContext = window.AudioContext || window.webkitAudioContext;

var audioCtx = new AudioContext();

var oscillator = audioCtx.createOscillator();
var gainNode = audioCtx.createGain();

oscillator.connect(gainNode);
gainNode.connect(audioCtx.destination);

oscillator.context;
oscillator.numberOfInputs;
oscillator.numberOfOutputs;
oscillator.channelCount;</pre>

<h2 id="Specifications">Specifications</h2>

<table class="standard-table">
 <tbody>
  <tr>
   <th scope="col">Specification</th>
   <th scope="col">Status</th>
   <th scope="col">Comment</th>
  </tr>
  <tr>
   <td>{{SpecName('Web Audio API', '#the-audionode-interface', 'AudioNode')}}</td>
   <td>{{Spec2('Web Audio API')}}</td>
   <td> </td>
  </tr>
 </tbody>
</table>

<h2 id="Browser_compatibility">Browser compatibility</h2>

{{Compat}}

<h2 id="See_also">See also</h2>

<ul>
 <li><a href="/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API">Using the Web Audio API</a></li>
</ul>
